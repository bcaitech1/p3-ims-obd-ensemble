{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trash_seg_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "543ad93940fe4818aba0b61fd76a18e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85b0960742da4c73982950e8b30afd78",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_868c3e5eb2d34112b31b0f1d4551504c",
              "IPY_MODEL_60fcd8187ac4446bad51c0dacd1afb26"
            ]
          }
        },
        "85b0960742da4c73982950e8b30afd78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "868c3e5eb2d34112b31b0f1d4551504c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2a45ba369f0e4f1190798d79a4762420",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 196466866,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 196466866,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f61bbd87adba4532bbfb33ce907e5520"
          }
        },
        "60fcd8187ac4446bad51c0dacd1afb26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a470d78f21954d4e8f3dd99c4aadd52c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 187M/187M [09:12&lt;00:00, 356kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eebf27e1ad0b49dcb7a98ebb67bbf800"
          }
        },
        "2a45ba369f0e4f1190798d79a4762420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f61bbd87adba4532bbfb33ce907e5520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a470d78f21954d4e8f3dd99c4aadd52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eebf27e1ad0b49dcb7a98ebb67bbf800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZx9ELQBJT-E",
        "outputId": "fb19231d-4f2a-4e27-db44-57fb07866497"
      },
      "source": [
        "!pip install segmentation_models_pytorch\n",
        "!pip install -q -U albumentations\n",
        "!pip install timm\n",
        "!pip install adamp\n",
        "!pip install neptune-client\n",
        "# !pip install git+https://github.com/zhanghang1989/PyTorch-Encoding.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/54/8953f9f7ee9d451b0f3be8d635aa3a654579abf898d17502a090efe1155a/segmentation_models_pytorch-0.1.3-py3-none-any.whl (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 51kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.9.1+cu101)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting timm==0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2d/39ecc56fbb202e1891c317e8e44667299bc3b0762ea2ed6aaaa2c2f6613c/timm-0.3.2-py3-none-any.whl (244kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 17.7MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.19.5)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.8.1+cu101)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision>=0.3.0->segmentation_models_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n",
            "Building wheels for collected packages: pretrainedmodels, efficientnet-pytorch\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp37-none-any.whl size=60963 sha256=d798b8728675da454ea703c2edf6c274cd1e3d33ca0f608cba8ae8e1fc4eb82f\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp37-none-any.whl size=12420 sha256=da95d549d87a11dac0697c3c75d40c3e6bcd3b49de0619beeb567bbfbb0d76ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built pretrainedmodels efficientnet-pytorch\n",
            "Installing collected packages: munch, pretrainedmodels, timm, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.3 timm-0.3.2\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 136kB/s \n",
            "\u001b[K     |████████████████████████████████| 952kB 56.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from timm) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Collecting adamp\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/56/182b8c93f18feb0244b83f9b2eff1c6b036c04d4c3880e8d222750b0d5e5/adamp-0.3.0.tar.gz\n",
            "Building wheels for collected packages: adamp\n",
            "  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adamp: filename=adamp-0.3.0-cp37-none-any.whl size=5999 sha256=f982856377b90f925155350ae3e487a3e5370e18e521418a199b63dca6f4d8af\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/89/67/879fe55977ebcbfaa5b929eb111af7fe11eb3552867850dd76\n",
            "Successfully built adamp\n",
            "Installing collected packages: adamp\n",
            "Successfully installed adamp-0.3.0\n",
            "Collecting neptune-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/d9/9cb3b43a99e84f40803981f88b4d1ff781e775d9140abb22dfe378a5846b/neptune-client-0.9.5.tar.gz (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 13.3MB/s \n",
            "\u001b[?25hCollecting bravado\n",
            "  Downloading https://files.pythonhosted.org/packages/21/ed/03b0c36b5bcafbe2938ed222f9a164a6c0367ce99a9d2d502e462853571d/bravado-11.0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.1.5)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting PyJWT\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/32/d5d3cab27fee7f6b22d7cd7507547ae45d52e26030fa77d1f83d0526c6e5/PyJWT-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n",
            "Collecting websocket-client>=0.35.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (20.9)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n",
            "Collecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/04/377418ac1e530ce2a196b54c6552c018fdf1fe776718053efb1f216bffcd/simplejson-3.17.2-cp37-cp37m-manylinux2010_x86_64.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 57.6MB/s \n",
            "\u001b[?25hCollecting monotonic\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.7.4.3)\n",
            "Collecting bravado-core>=5.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/11/18e9d28a156c33f2d5f15a5e155dc7130250acb0a569255a2b6b307b596d/bravado_core-5.17.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.13)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (2.4.7)\n",
            "Collecting jsonref\n",
            "  Downloading https://files.pythonhosted.org/packages/07/92/f8e4ac824b14af77e613984e480fa818397c72d4141fc466decb26752749/jsonref-0.2-py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2.6.0)\n",
            "Collecting swagger-spec-validator>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/09/de/e78cefbf5838b434b63a789264b79821cb2267f1498fbed23ef8590133e4/swagger_spec_validator-2.7.3-py2.py3-none-any.whl\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Collecting webcolors; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/12/05/3350559de9714b202e443a9e6312937341bd5f79f4e4f625744295e7dd17/webcolors-1.11.1-py3-none-any.whl\n",
            "Collecting rfc3987; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/65/d4/f7407c3d15d5ac779c3dd34fbbc6ea2090f77bd7dd12f207ccf881551208/rfc3987-1.3.8-py2.py3-none-any.whl\n",
            "Collecting strict-rfc3339; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/56/e4/879ef1dbd6ddea1c77c0078cd59b503368b0456bcca7d063a870ca2119d3/strict-rfc3339-0.7.tar.gz\n",
            "Building wheels for collected packages: neptune-client, future, strict-rfc3339\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.9.5-py2.py3-none-any.whl size=372957 sha256=eff9bc75fab24073138176a716049faa42f6dcc6627ee3c6f9965263a4a0a0b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/b1/b8/42228d4e6f34bde7de247c8adcb64fa58c890bed5491e2ec8a\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=9f8dab73bae8a714d054e7f41a285eb8c37e597868aa930ba6e3aa81443f9735\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-cp37-none-any.whl size=18121 sha256=563f13bc4cafad9afc056ac80149e3dcf80463e3953037a017106fa6861f9b77\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/af/c9/b6e9fb5f9b2470e4ed2a7241c9ab3a8cdd3bc8555ae02ca2e6\n",
            "Successfully built neptune-client future strict-rfc3339\n",
            "Installing collected packages: simplejson, monotonic, jsonref, swagger-spec-validator, bravado-core, bravado, future, PyJWT, websocket-client, smmap, gitdb, GitPython, neptune-client, webcolors, rfc3987, strict-rfc3339\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed GitPython-3.1.14 PyJWT-2.1.0 bravado-11.0.3 bravado-core-5.17.0 future-0.18.2 gitdb-4.0.7 jsonref-0.2 monotonic-1.6 neptune-client-0.9.5 rfc3987-1.3.8 simplejson-3.17.2 smmap-4.0.0 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 webcolors-1.11.1 websocket-client-0.58.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y_xFFOvEfvY",
        "outputId": "908c6125-a5dc-456a-b935-29617cc89c8a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  2 15:45:36 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vjrPOwLJnRv"
      },
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from adamp import AdamP\n",
        "\n",
        "import math\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "# from fastai.vision.all import *\n",
        "\n",
        "from sklearn.model_selection import GroupKFold, KFold\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts, _LRScheduler\n",
        "from scipy.ndimage.interpolation import zoom\n",
        "import albumentations as A\n",
        "from torch.nn import functional as F\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import timm\n",
        "\n",
        "import neptune\n",
        "# import encoding"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiYA7eeXLp05"
      },
      "source": [
        "# run = neptune.init('vvvic313/trash-segmentation', api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlODg2NjVlNC01YjIxLTQ3ZGItYWVkYS05MGFiYWNjMGI2YjUifQ==')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4FWp2qrLmT_"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5x-rujXLmWN"
      },
      "source": [
        "CFG = {\n",
        "    \"img_size\": 512,\n",
        "    \"num_workers\": 4,\n",
        "    \"scheduler\": \"Warmup\",\n",
        "    \"epochs\": 20,\n",
        "    \"criterion\": \"CELoss\",\n",
        "    \"decoder\": \"DeepLabV3Plus\",\n",
        "    \"encoder\": \"resnext50_32x4d\",\n",
        "    \"pretrained\": \"imagenet\",\n",
        "    \"lr\": 1e-4,\n",
        "    \"batch_size\": 8,\n",
        "    \"weight_decay\": 1e-6,\n",
        "    \"gradient_accumulation_steps\": 4,\n",
        "    \"seed\": 42,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"mean\": (0.485, 0.456, 0.406),\n",
        "    \"std\": (0.229, 0.224, 0.225),\n",
        "    \"mix_prob\": 0.5,\n",
        "    \"pseudo_label\": True\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytCrrgqLmYY"
      },
      "source": [
        "seed_everything(CFG['seed'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT44V4irLma_"
      },
      "source": [
        "def get_train_augmentations():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(p = 0.5),\n",
        "        A.VerticalFlip(p = 0.5),\n",
        "        A.ShiftScaleRotate(p=0.5),\n",
        "        A.Cutout(),\n",
        "        A.RandomBrightnessContrast(),\n",
        "        A.Normalize(mean=CFG['mean'], std=CFG['std'], max_pixel_value=255.0, p=1.0),\n",
        "        ToTensorV2()\n",
        "    ], p=1.0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BshBGtjBo1RO"
      },
      "source": [
        "# neptune.create_experiment(name=\"day_0502\", params=CFG)\n",
        "# neptune.append_tag(\"effb3\", \"deeplabv3+\",  \"heavy_aug\", \"fold2\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbXfehKeLmda"
      },
      "source": [
        "def get_validation_augmentations():\n",
        "    return A.Compose([\n",
        "        A.Normalize(mean=CFG['mean'], std=CFG['std'], max_pixel_value=255.0, p=1.0),\n",
        "        ToTensorV2()\n",
        "    ],p=1.0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec-1gT4BL3wX"
      },
      "source": [
        "class TrashDataset(Dataset):\n",
        "    def __init__(self, df, root=\"/content/drive/MyDrive/trash_segmentation/data/\", mode=\"train\", transform=None):\n",
        "        self.df = df.reset_index(drop=True).copy()\n",
        "        self.mode = mode\n",
        "        self.transform = transform\n",
        "        self.root = root\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.root + self.df.iloc[idx]['filepath']\n",
        "        imgs = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        \n",
        "        if self.mode==\"train\" or self.mode==\"val\":\n",
        "            mask_path = self.root + self.df.iloc[idx]['masks']\n",
        "            masks = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "            transformed = self.transform(image=imgs, mask=masks)\n",
        "            imgs = transformed[\"image\"]\n",
        "            masks = transformed[\"mask\"]\n",
        "\n",
        "            return imgs, masks\n",
        "        \n",
        "        elif self.mode == \"test\":\n",
        "            transformed = self.transform(image=imgs)\n",
        "            imgs = transformed[\"image\"]\n",
        "            \n",
        "            return imgs, 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_cpkGAVL3y2"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/trash_segmentation/data/train.csv\")\n",
        "\n",
        "if CFG['psuedo_label']:\n",
        "    additional_df = pd.read_csv(\"/content/drive/MyDrive/trash_segmentation/data/test.csv\")\n",
        "    df = pd.concat([df, additional_df], ignore_index=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVpCSoBFFpq1"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS52zkpML31J"
      },
      "source": [
        "def prepare_dataloader(df, fold):\n",
        "    train_ids = df[~df.Folds.isin(fold)]\n",
        "    val_ids = df[df.Folds.isin(fold)]\n",
        "\n",
        "    train_ds = TrashDataset(train_ids, mode=\"train\", transform=get_train_augmentations())\n",
        "    val_ds = TrashDataset(val_ids, mode=\"val\", transform=get_validation_augmentations())\n",
        "    \n",
        "    train_loader = DataLoader(train_ds, \n",
        "                              batch_size=CFG[\"batch_size\"], \n",
        "                              shuffle=True, \n",
        "                              num_workers=CFG[\"num_workers\"],\n",
        "                              collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_ds,\n",
        "                            batch_size=CFG[\"batch_size\"],\n",
        "                            shuffle=False,\n",
        "                            num_workers=CFG[\"num_workers\"],\n",
        "                            collate_fn=collate_fn)\n",
        "    \n",
        "    return train_loader, val_loader"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcIKkNoOL33e"
      },
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1e-7):\n",
        "        \n",
        "        inputs = inputs.log_softmax(dim=1).exp()\n",
        "        \n",
        "        bs = targets.size(0)\n",
        "        num_classes = inputs.size(1)\n",
        "        dims = (0, 2)\n",
        "        \n",
        "        \n",
        "        targets = targets.view(bs, -1)\n",
        "        inputs = inputs.view(bs, num_classes, -1)\n",
        "        \n",
        "        targets = F.one_hot(targets, num_classes)\n",
        "        targets = targets.permute(0, 2, 1)\n",
        "        \n",
        "        intersection = torch.sum(inputs * targets, dim=dims)\n",
        "        cardinality = torch.sum(inputs + targets, dim=dims)\n",
        "        \n",
        "        dice = (2.0 * intersection + smooth) / (cardinality + smooth)\n",
        "        \n",
        "        loss = 1 - dice\n",
        "        \n",
        "        return loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hJapCwQL35v"
      },
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        \n",
        "    def forward(self, inputs, targets, smooth=1e-7):\n",
        "        \n",
        "#         ce_loss = nn.CrossEntropy()(inputs, targets)\n",
        "        ce_loss = F.cross_entropy(inputs, targets)\n",
        "        \n",
        "        inputs = inputs.log_softmax(dim=1).exp()\n",
        "        \n",
        "        bs = targets.size(0)\n",
        "        num_classes = inputs.size(1)\n",
        "        dims = (0, 2)\n",
        "        \n",
        "        targets = targets.view(bs, -1)\n",
        "        inputs = inputs.view(bs, num_classes, -1)\n",
        "        \n",
        "        targets = F.one_hot(targets, num_classes)\n",
        "        targets = targets.permute(0, 2, 1)\n",
        "        \n",
        "        intersection = torch.sum(inputs * targets, dim=dims)\n",
        "        cardinality = torch.sum(inputs + targets, dim=dims)\n",
        "        \n",
        "        dice = (2.0 * intersection + smooth) / (cardinality + smooth)\n",
        "        \n",
        "        loss = 1 - dice\n",
        "\n",
        "        mask = targets.sum(dims) > 0\n",
        "        loss *= mask.to(loss.dtype)\n",
        "\n",
        "\n",
        "        return (loss.mean()) +  ce_loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE3N-Rf9L38E"
      },
      "source": [
        "criterion = None\n",
        "if CFG['criterion'] == \"DiceLoss\":\n",
        "    criterion = DiceLoss()\n",
        "elif CFG['criterion'] == \"CELoss\":\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "elif CFG['criterion'] == \"CustomLoss\":\n",
        "    criterion = CustomLoss()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCzJGRmkL3-p"
      },
      "source": [
        "class CustomCosineAnnealingWarmUpRestarts(_LRScheduler):\n",
        "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
        "        if T_0 <= 0 or not isinstance(T_0, int):\n",
        "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
        "        if T_mult < 1 or not isinstance(T_mult, int):\n",
        "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
        "        if T_up < 0 or not isinstance(T_up, int):\n",
        "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
        "        self.T_0 = T_0\n",
        "        self.T_mult = T_mult\n",
        "        self.base_eta_max = eta_max\n",
        "        self.eta_max = eta_max\n",
        "        self.T_up = T_up\n",
        "        self.T_i = T_0\n",
        "        self.gamma = gamma\n",
        "        self.cycle = 0\n",
        "        self.T_cur = last_epoch\n",
        "        super(CustomCosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
        "        \n",
        "    \n",
        "    def get_lr(self):\n",
        "        if self.T_cur == -1:\n",
        "            return self.base_lrs\n",
        "        elif self.T_cur < self.T_up:\n",
        "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
        "                    for base_lr in self.base_lrs]\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch + 1\n",
        "            self.T_cur = self.T_cur + 1\n",
        "            if self.T_cur >= self.T_i:\n",
        "                self.cycle += 1\n",
        "                self.T_cur = self.T_cur - self.T_i\n",
        "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
        "        else:\n",
        "            if epoch >= self.T_0:\n",
        "                if self.T_mult == 1:\n",
        "                    self.T_cur = epoch % self.T_0\n",
        "                    self.cycle = epoch // self.T_0\n",
        "                else:\n",
        "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
        "                    self.cycle = n\n",
        "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
        "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
        "            else:\n",
        "                self.T_i = self.T_0\n",
        "                self.T_cur = epoch\n",
        "                \n",
        "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
        "        self.last_epoch = math.floor(epoch)\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ddlE6fwMMSB"
      },
      "source": [
        "def _fast_hist(label_true, label_pred, n_class):\n",
        "    mask = (label_true >= 0) & (label_true < n_class)\n",
        "    hist = np.bincount(\n",
        "        n_class * label_true[mask].astype(int) +\n",
        "        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n",
        "    return hist\n",
        "\n",
        "\n",
        "def label_accuracy_score_(label_trues, label_preds, n_class):\n",
        "    \"\"\"Returns accuracy score evaluation result.\n",
        "      - overall accuracy\n",
        "      - mean accuracy\n",
        "      - mean IU\n",
        "      - fwavacc\n",
        "    \"\"\"\n",
        "    hist = np.zeros((n_class, n_class))\n",
        "    for lt, lp in zip(label_trues, label_preds):\n",
        "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
        "    acc = np.diag(hist).sum() / hist.sum()\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
        "    acc_cls = np.nanmean(acc_cls)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        iu = np.diag(hist) / (\n",
        "            hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist)\n",
        "        )\n",
        "    mean_iu = np.nanmean(iu)\n",
        "    freq = hist.sum(axis=1) / hist.sum()\n",
        "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
        "    return acc, acc_cls, mean_iu, fwavacc"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n8Iee6WMMUR"
      },
      "source": [
        "def label_accuracy_score(hist):\n",
        "    \"\"\"\n",
        "    Returns accuracy score evaluation result.\n",
        "      - [acc]: overall accuracy\n",
        "      - [acc_cls]: mean accuracy\n",
        "      - [mean_iu]: mean IU\n",
        "      - [fwavacc]: fwavacc\n",
        "    \"\"\"\n",
        "    acc = np.diag(hist).sum() / hist.sum()\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
        "    acc_cls = np.nanmean(acc_cls)\n",
        "\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
        "    mean_iu = np.nanmean(iu)\n",
        "\n",
        "    freq = hist.sum(axis=1) / hist.sum()\n",
        "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
        "    return acc, acc_cls, mean_iu, fwavacc"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgU8J0coMMWX"
      },
      "source": [
        "def add_hist(hist, label_trues, label_preds, n_class):\n",
        "    \"\"\"\n",
        "        stack hist(confusion matrix)\n",
        "    \"\"\"\n",
        "\n",
        "    for lt, lp in zip(label_trues, label_preds):\n",
        "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
        "\n",
        "    return hist"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQTFVol0RRnv"
      },
      "source": [
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1.0 - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return bbx1, bby1, bbx2, bby2"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFMtLMfxPMIV"
      },
      "source": [
        "def cutmix(data, target, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_target = target[indices]\n",
        "\n",
        "    lam = np.clip(np.random.beta(alpha, alpha), 0.3, 0.4)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
        "    new_data = data.clone()\n",
        "    new_target = target.clone()\n",
        "    new_data[:, :, bby1:bby2, bbx1:bbx2] = data[indices, :, bby1:bby2, bbx1:bbx2]\n",
        "    new_target[:, bby1:bby2, bbx1:bbx2] = target[indices, bby1:bby2, bbx1:bbx2]\n",
        "    # adjust lambda to exactly match pixel ratio\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
        "    \n",
        "\n",
        "    return new_data, new_target"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxlrGoiVMMY4"
      },
      "source": [
        "def train_one_epoch(epoch, model, device, optimizer, criterion, train_loader, scheduler):\n",
        "    model.train()\n",
        "    running_loss = None\n",
        "    \n",
        "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True)\n",
        "\n",
        "    for step, (imgs, masks) in pbar:\n",
        "\n",
        "        if (step+1) == (len(train_loader)):\n",
        "            continue\n",
        "        mix_decision = np.random.rand()\n",
        "        imgs = torch.stack(imgs)\n",
        "        masks = torch.stack(masks)\n",
        "        imgs = imgs.to(device).float()\n",
        "        masks = masks.to(device).long()\n",
        "        \n",
        "        if mix_decision < CFG['mix_prob']:\n",
        "            imgs, masks = cutmix(imgs, masks, 1.0)\n",
        "\n",
        "        with autocast():\n",
        "            model.to(device)\n",
        "            mask_preds = model(imgs)\n",
        "            loss = criterion(mask_preds, masks) / CFG['gradient_accumulation_steps']\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # loss.backward()\n",
        "\n",
        "            if running_loss is None:\n",
        "                running_loss = loss.item() * CFG['gradient_accumulation_steps']\n",
        "            else:\n",
        "                running_loss = running_loss * 0.99 + loss.item() * CFG['gradient_accumulation_steps'] * 0.01\n",
        "\n",
        "            if ((step + 1) % CFG[\"gradient_accumulation_steps\"]==0) or ((step+1) == (len(train_loader))):\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                # optimizer.zero_grad()\n",
        "                # optimizer.step()                            \n",
        "                optimizer.zero_grad() \n",
        "                description = f\"epoch {epoch} loss: {running_loss: .4f}\"\n",
        "                pbar.set_description(description)\n",
        "                \n",
        "    scheduler.step()        "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWRZ04KxMMbX"
      },
      "source": [
        "def valid_one_epoch(epoch, model, device, criterion, val_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    total_loss = 0\n",
        "    running_loss = None\n",
        "    cnt = 0\n",
        "    mIoU_list = []\n",
        "    pbar = tqdm(enumerate(val_loader), total=len(val_loader), position=0, leave=True)\n",
        "    hist = np.zeros((12, 12))\n",
        "    for step, (imgs, masks) in pbar:\n",
        "        if (step+1) == (len(train_loader)):\n",
        "            continue\n",
        "        imgs = torch.stack(imgs)\n",
        "        masks = torch.stack(masks)\n",
        "        imgs = imgs.to(device).float()\n",
        "        masks = masks.to(device).long()\n",
        "        \n",
        "        cnt += 1\n",
        "\n",
        "        mask_preds = model(imgs)\n",
        "        # print(f\"{mask_preds.shape}       \")\n",
        "        loss = criterion(mask_preds, masks)\n",
        "\n",
        "        mask_preds = torch.argmax(mask_preds, dim=1).detach().cpu().numpy()\n",
        "        # print(mask_preds.shape)\n",
        "\n",
        "        mIoU = label_accuracy_score_(masks.detach().cpu().numpy(), mask_preds, n_class=12)[2]\n",
        "        mIoU_list.append(mIoU)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "            \n",
        "        if running_loss is None:\n",
        "            running_loss = loss.item()\n",
        "        else:\n",
        "            running_loss = running_loss * 0.99 + loss.item() * 0.01\n",
        "\n",
        "        description = f'epoch {epoch} Loss: {running_loss:.4f}, mIoU: {np.mean(mIoU_list):.4f}'\n",
        "        pbar.set_description(description)\n",
        "\n",
        "    return total_loss/cnt, np.mean(mIoU_list)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf1S2tfnMMdw"
      },
      "source": [
        "FOLDS = 5\n",
        "kf = KFold(FOLDS, shuffle=True, random_state=CFG['seed'])\n",
        "df[\"Folds\"] = 0\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
        "    df.loc[val_idx, 'Folds'] = fold"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgls-tqKMS0V"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERQDJsYZMS2o"
      },
      "source": [
        "def create_folder(directory):\n",
        "    try:\n",
        "        os.makedirs(directory)\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "543ad93940fe4818aba0b61fd76a18e6",
            "85b0960742da4c73982950e8b30afd78",
            "868c3e5eb2d34112b31b0f1d4551504c",
            "60fcd8187ac4446bad51c0dacd1afb26",
            "2a45ba369f0e4f1190798d79a4762420",
            "f61bbd87adba4532bbfb33ce907e5520",
            "a470d78f21954d4e8f3dd99c4aadd52c",
            "eebf27e1ad0b49dcb7a98ebb67bbf800"
          ]
        },
        "id": "KMzx6Tb8MS43",
        "outputId": "61e95043-cc9a-4654-95f2-01ac9bffdba6"
      },
      "source": [
        "for fold in range(FOLDS):\n",
        "    # if fold != 0:\n",
        "    #   continue\n",
        "    print(f\"{fold} fold start\")\n",
        "    \n",
        "    if CFG['decoder'] == \"Unetpp\":\n",
        "        model = smp.UnetPlusPlus(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n",
        "    elif CFG['decoder'] == 'DeepLabV3Plus':\n",
        "        model = smp.DeepLabV3Plus(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n",
        "    elif CFG['decoder'] == 'DeepLabV3':\n",
        "        model = smp.DeepLabV3(CFG['encoder'], encoder_weights=CFG['pretrained'], in_channels=3, classes=12).to(device)\n",
        "    elif CFG['decoder'] == \"UperNet\":\n",
        "        model = encoding.models.sseg.UperNet(12, CFG['encoder'], aux=False)\n",
        "    \n",
        "    if CFG['scheduler'] == \"Warmup\":\n",
        "        if CFG['optimizer'] == \"Adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=0, weight_decay=CFG['weight_decay'])\n",
        "            scheduler = CustomCosineAnnealingWarmUpRestarts(optimizer, T_0=CFG['epochs'], T_mult=1, eta_max=CFG['lr'], T_up=CFG['epochs']//10, gamma=1.)\n",
        "    else:\n",
        "        if CFG['optimizer'] == \"Adam\":\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
        "    \n",
        "    scaler = GradScaler()\n",
        "    train_loader, valid_loader = prepare_dataloader(df, [fold])\n",
        "    \n",
        "    best_mIoU = 0\n",
        "    num_epochs = CFG['epochs']\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        train_one_epoch(epoch, model, device, optimizer, criterion, train_loader, scheduler)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            epoch_loss, mIoU = valid_one_epoch(epoch, model, device, criterion, valid_loader)\n",
        "\n",
        "        # neptune.log_metric(f\"fold{fold} epoch loss\", epoch_loss)\n",
        "        # neptune.log_metric(f\"fold{fold} mIoU\", mIoU)\n",
        "\n",
        "        if best_mIoU < mIoU:\n",
        "            best_mIoU = mIoU\n",
        "            dir_ = f\"/content/drive/MyDrive/trash_segmentation/models\"\n",
        "            create_folder(dir_)\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'optimizer': optimizer.state_dict(),\n",
        "                        'scheduler': scheduler.state_dict()\n",
        "                        }, f\"{dir_}/{CFG['encoder']}_{fold}.pth\")\n",
        "            print(\"model is saved\")\n",
        "        print(\"\")\n",
        "\n",
        "    # neptune.log_metric(f\"fold {fold} Best mIoU\", best_mIoU)\n",
        "    del model, optimizer, train_loader, valid_loader, scheduler\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "# neptune.stop()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 fold start\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext101_32x4d-3b2fe3d8.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "543ad93940fe4818aba0b61fd76a18e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=196466866.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 loss:  2.5130: 100%|██████████| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 0 Loss: 2.5256, mIoU: 0.0101: 100%|██████████| 82/82 [01:39<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 loss:  1.2955: 100%|██████████| 328/328 [08:25<00:00,  1.54s/it]\n",
            "epoch 1 Loss: 0.9083, mIoU: 0.2437: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 loss:  0.7380: 100%|██████████| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 2 Loss: 0.5573, mIoU: 0.3502: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 loss:  0.5439: 100%|██████████| 328/328 [08:26<00:00,  1.54s/it]\n",
            "epoch 3 Loss: 0.4575, mIoU: 0.3867: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4 loss:  0.4383: 100%|██████████| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 4 Loss: 0.3703, mIoU: 0.4215: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5 loss:  0.3869: 100%|██████████| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 5 Loss: 0.3413, mIoU: 0.4302: 100%|██████████| 82/82 [01:38<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 6 loss:  0.3373: 100%|██████████| 328/328 [08:24<00:00,  1.54s/it]\n",
            "epoch 6 Loss: 0.3447, mIoU: 0.4309: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 7 loss:  0.2946: 100%|██████████| 328/328 [08:23<00:00,  1.53s/it]\n",
            "epoch 7 Loss: 0.3780, mIoU: 0.4472: 100%|██████████| 82/82 [01:39<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 8 loss:  0.2684: 100%|██████████| 328/328 [08:26<00:00,  1.54s/it]\n",
            "epoch 8 Loss: 0.3386, mIoU: 0.4511: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 9 loss:  0.2486: 100%|██████████| 328/328 [08:26<00:00,  1.54s/it]\n",
            "epoch 9 Loss: 0.3442, mIoU: 0.4581: 100%|██████████| 82/82 [01:39<00:00,  1.21s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 10 loss:  0.2345: 100%|██████████| 328/328 [08:25<00:00,  1.54s/it]\n",
            "epoch 10 Loss: 0.3719, mIoU: 0.4453: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 11 loss:  0.2050: 100%|██████████| 328/328 [08:23<00:00,  1.53s/it]\n",
            "epoch 11 Loss: 0.3569, mIoU: 0.4694: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 12 loss:  0.1977: 100%|██████████| 328/328 [08:23<00:00,  1.54s/it]\n",
            "epoch 12 Loss: 0.3181, mIoU: 0.4629: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 13 loss:  0.1871: 100%|██████████| 328/328 [08:21<00:00,  1.53s/it]\n",
            "epoch 13 Loss: 0.2986, mIoU: 0.4734: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 14 loss:  0.1598: 100%|██████████| 328/328 [08:21<00:00,  1.53s/it]\n",
            "epoch 14 Loss: 0.3092, mIoU: 0.4728: 100%|██████████| 82/82 [01:38<00:00,  1.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 15 loss:  0.1691: 100%|██████████| 328/328 [08:21<00:00,  1.53s/it]\n",
            "epoch 15 Loss: 0.3210, mIoU: 0.4646: 100%|██████████| 82/82 [01:37<00:00,  1.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 16 loss:  0.1626: 100%|██████████| 328/328 [08:19<00:00,  1.52s/it]\n",
            "epoch 16 Loss: 0.3097, mIoU: 0.4679: 100%|██████████| 82/82 [01:36<00:00,  1.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 17 loss:  0.1607: 100%|██████████| 328/328 [08:20<00:00,  1.53s/it]\n",
            "epoch 17 Loss: 0.3079, mIoU: 0.4654: 100%|██████████| 82/82 [01:37<00:00,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 18 loss:  0.1577: 100%|██████████| 328/328 [08:17<00:00,  1.52s/it]\n",
            "epoch 18 Loss: 0.2993, mIoU: 0.4668: 100%|██████████| 82/82 [01:37<00:00,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 19 loss:  0.1591: 100%|██████████| 328/328 [08:17<00:00,  1.52s/it]\n",
            "epoch 19 Loss: 0.3033, mIoU: 0.4736: 100%|██████████| 82/82 [01:36<00:00,  1.18s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model is saved\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGV2VIve5JvU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}